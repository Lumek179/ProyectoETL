{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "528e4caa-2475-46b3-a6aa-dbfe5de7c0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import elasticsearch\n",
    "from elasticsearch import Elasticsearch, helpers, exceptions\n",
    "from ssl import create_default_context\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "class ConnectElasticsearch:\n",
    "\n",
    "    __time_scroll                 =  '1m'\n",
    "    __resp                        =  ''\n",
    "    __scroll                      =  '1s'  # time value for search\n",
    "    __rest_total_hits_as_int      =  True\n",
    "    __scheme                      =  \"https\"\n",
    "    __context_dir                 =  \"/etc/pki/ca-trust/source/anchors/elastic-stack-ca.pem\"\n",
    "    \n",
    "    \"\"\" \n",
    "    Se define la clase de conexion a Elasticsearch\n",
    "    \"\"\"   \n",
    "    def __init__( self, context_dir  =  None, user  =  'elastic', pwd  =  'elastic', port  =  9200,  ):\n",
    "        \n",
    "        if not context_dir is None :\n",
    "            self.__context                 =  create_default_context(  cafile  =  context_dir  )\n",
    "            self.__context.check_hostname  =  False\n",
    "            \n",
    "        self.__user                   =  user\n",
    "        self.__pwd                    =  pwd\n",
    "        self.__http_auth              =  (  self.__user, self.__pwd )\n",
    "        self.__port                   =  port\n",
    "        self.__ips                    =  [  '192.168.200.23', '192.168.200.24', '192.168.200.25'  ]\n",
    "\n",
    "    \"\"\"\n",
    "    metodos de get y set\n",
    "    \"\"\"  \n",
    "\n",
    "    def get_indexName(self):\n",
    "        return self.indexName\n",
    "    \n",
    "    def set_indexName( self,  indexName  ):\n",
    "         self.indexName  =  indexName\n",
    "            \n",
    "                \n",
    "    def get_es(self):\n",
    "        return self.__es\n",
    "    \n",
    "    def set_result(self):\n",
    "        \n",
    "        self.__resp   = self.__es.search(  index       = self.nameIndex,\n",
    "                                           body        = self.__query,\n",
    "                                           scroll      = self.__time_scroll # time value for search 1 milisecond\n",
    "                                        )\n",
    "    def set_id_scroll(self):\n",
    "        self.__idScroll  =  self.__resp [ '_scroll_id' ] \n",
    "    \n",
    "    def get_id_scroll(self):\n",
    "        return self.__idScroll  \n",
    "    \n",
    "    def show_id_scroll(self):\n",
    "        print(  \"idScroll:\"  ,  self.get_id_scroll(  ) )\n",
    "        \n",
    "    def get_hits_size_ini(self):\n",
    "        return len(  self.__resp[ \"hits\" ][ \"hits\" ]  )\n",
    "    \n",
    "    def get_total_hits(self):\n",
    "        return self.__resp[ \"hits\" ][ \"total\" ][ \"value\" ] \n",
    "    \n",
    "    def get_result_scroll(self):\n",
    "        \n",
    "        return self.__es.scroll(\n",
    "                                 scroll_id              = self.__idScroll,\n",
    "                                 scroll                 = self.__scroll,\n",
    "                                 rest_total_hits_as_int = self.__rest_total_hits_as_int\n",
    "                                )[\"hits\"][\"hits\"]\n",
    "\n",
    "    \n",
    "    def get_aggs(self):\n",
    "        \n",
    "        lenAggs  =  len(  self.__resp[ \"aggregations\" ][ \"groupby\" ][ \"buckets\" ]  )\n",
    "        \n",
    "        if lenAggs  !=  0:\n",
    "            \n",
    "            list_aggs  =  self.__resp[ \"aggregations\" ][ \"groupby\" ][ \"buckets\" ]\n",
    "            \n",
    "            if \"after_key\" in resp[ \"aggregations\" ][ \"groupby\" ]:\n",
    "                \n",
    "                after  =  resp[ \"aggregations\" ][ \"groupby\" ][ \"after_key\" ]\n",
    "            else:\n",
    "                after  =  { }\n",
    "        else:\n",
    "            list_aggs  =  [ ]\n",
    "            after      =  { }\n",
    "\n",
    "        return list_aggs, after\n",
    "    \n",
    "    def set_query(  self,  search_query  ):\n",
    "        self.__query  =  search_query\n",
    "        \n",
    "    def get_query(self):\n",
    "        return self.__query\n",
    "        \n",
    "    def set_reindex_query(  self,  reindex_query  ):\n",
    "        self.__queryReindex  =  reindex_query\n",
    "    \n",
    "    \"\"\"\n",
    "    metodos print\n",
    "    \"\"\"\n",
    "    def show_total_hits(self):\n",
    "        print ( \"total_hits_consulta:\",  self.__resp[ \"hits\" ][ \"total\" ][ \"value\" ]  )\n",
    "        \n",
    "    def show_total_hits_ini(self):\n",
    "        print ( \"total_hits_inicial:\",  len( self.__resp[ \"hits\" ][ \"hits\" ]  )  )        \n",
    "    \n",
    "    \"\"\"\n",
    "    metodos de conexion y desconexion\n",
    "    \"\"\"\n",
    "    def connect(self):\n",
    "        \n",
    "        try:\n",
    "            self.__es  =  Elasticsearch( self.__ips,\n",
    "                                         http_auth    =  self.__http_auth,\n",
    "                                         scheme       =  self.__scheme,\n",
    "                                         port         =  self.__port,\n",
    "                                         ssl_context  =  self.__context)\n",
    "            self.info  =  self.__es.info()\n",
    "            \n",
    "        except exceptions.ConnectionError as err:\n",
    "            \n",
    "            print( 'EC error Connect: ', err)\n",
    "            self.__es  =  None\n",
    "            \n",
    "    def close_connect(self):\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            self.__es.close()\n",
    "            \n",
    "        except exceptions as err:\n",
    "            \n",
    "            print( 'EC error CloseConnect: ', err)\n",
    "\n",
    "    \"\"\"\n",
    "    metodos de bulk: carga, actualizacion, eliminacion\n",
    "    \"\"\"\n",
    "    def bulk_data(  self,  json_list  ):\n",
    "        \n",
    "        for doc in json_list:\n",
    "            _index= doc[\"indexName\"]\n",
    "            status_delete_key= doc.pop(\"indexName\",None)\n",
    "            if status_delete_key != None:\n",
    "                yield {\n",
    "                        \"_index\"   :  _index,\n",
    "                        \"_source\"  :  doc\n",
    "                }\n",
    "            \n",
    "    def bulk_data_update(  self,  json_list  ):\n",
    "        \n",
    "        for doc in json_list:\n",
    "            \n",
    "            yield {\n",
    "                     \"_op_type\"  :  \"update\",\n",
    "                     \"_index\"    :  self.nameIndex,\n",
    "                     \"_id\"       :  doc[  \"_id\"  ],\n",
    "                     \"doc\" :\n",
    "                           { \n",
    "                             \"attachment_filename\"        :  doc[\"attachment_filename\"],\n",
    "                             \"content_attachment.filename\":  doc[\"content_attachment.filename\"],\n",
    "                             \"status_read\"                :  doc[\"status_read\"],\n",
    "                             \"unique_id_file\"             :  doc[\"unique_id_file\"]\n",
    "                           }\n",
    "                  }\n",
    "    def bulk_data_update_doc(  self,  json_list  ):\n",
    "        #_doc_type = '_doc' no es necesario lo genera en automatico como _doc\n",
    "        for doc in json_list:\n",
    "            \n",
    "            _id                   =  doc[ \"_id\" ]\n",
    "            status_delete_key     =  doc.pop( \"_id\" , None )\n",
    "            \n",
    "            if status_delete_key  !=  None:\n",
    "                \n",
    "                yield {\n",
    "                        \"_op_type\" :  \"update\",\n",
    "                        \"_index\"   :  self.nameIndex,\n",
    "                        \"_id\"      :  _id,\n",
    "                        \"doc\"      :  doc\n",
    "                }\n",
    "    def bulk_data_delete(  self,  json_list  ):\n",
    "        #\"doc\":json.loads(doc[\"doc\"])\n",
    "        for doc in json_list:\n",
    "            # use un generador de rendimiento para que los datos no se carguen en la memoria\n",
    "            yield {\n",
    "                    \"_op_type\"  :  \"delete\",\n",
    "                    \"_index\"    :  self.nameIndex,\n",
    "                    \"_id\"       :  doc[ \"_id\" ]\n",
    "            }\n",
    "            \n",
    "    \n",
    "    \"\"\"\n",
    "    metodos de: carga, actualizacion, eliminacion\n",
    "    \"\"\"\n",
    "            \n",
    "    def load_data(  self,  final_json_list, indexName  ):\n",
    "        self.nameIndex  =  indexName\n",
    "        try:\n",
    "            \n",
    "            for success, action in helpers.streaming_bulk( self.__es, \n",
    "                                                           self.bulk_data(  final_json_list  ),\n",
    "                                                           raise_on_error      =  True,\n",
    "                                                           raise_on_exception  =  False,\n",
    "                                                           yield_ok            =  False,):\n",
    "\n",
    "                if not success:\n",
    "                    \n",
    "                    print( 'A document failed:', action )\n",
    "        except Exception as e:\n",
    "            \n",
    "            print( \"\\nERROR Load Data:\" , e  )\n",
    "\n",
    "            \n",
    "    def update_data(  self,  final_json_list  ):\n",
    "        self.nameIndex  =  indexName\n",
    "        try:\n",
    "            \n",
    "            for success, action in helpers.streaming_bulk(self.__es,\n",
    "                                                          self.bulk_data_update( final_json_list ),\n",
    "                                                          raise_on_error      =  True,\n",
    "                                                          raise_on_exception  =  False,\n",
    "                                                          yield_ok            =  False,):\n",
    "            \n",
    "                if not success:\n",
    "                    \n",
    "                    print( 'A document failed:' ,  action  )\n",
    "        except Exception as e:\n",
    "            \n",
    "            print(  \"\\nERROR Load Data Update:\"  ,  e  )\n",
    "            \n",
    "            \n",
    "    def update_doc(  self,  final_json_list,  indexName  ):\n",
    "        self.nameIndex  =  indexName\n",
    "        try:\n",
    "            for success, action in helpers.streaming_bulk(  self.__es,\n",
    "                                                            self.bulk_data_update_doc(  final_json_list  ),\n",
    "                                                            raise_on_error      =  True,\n",
    "                                                            raise_on_exception  =  False,\n",
    "                                                            yield_ok            =  False,):\n",
    "                #print(\"ok:\",success)\n",
    "                #print(\" action:\", action)\n",
    "                #pass\n",
    "                if not success:\n",
    "                    print(  'A document failed:',  action  )\n",
    "                    \n",
    "        except Exception as e:\n",
    "            \n",
    "            print(  \"\\nERROR Load Data Update:\",  e  )\n",
    "            \n",
    "            \n",
    "    def delete_data(self,  final_json_list, indexName):\n",
    "        self.nameIndex  =  indexName\n",
    "        try:\n",
    "            for success, action in helpers.streaming_bulk(self.__es,\n",
    "                                                          self.bulk_data_delete(  final_json_list  ),\n",
    "                                                          raise_on_error       =  True,\n",
    "                                                          raise_on_exception   =  False,\n",
    "                                                          yield_ok             =  False,):\n",
    "                print(  \"ok:\"  ,  success  )\n",
    "                #print(\" action:\", action)\n",
    "                #pass\n",
    "                if not success:\n",
    "                    \n",
    "                    print( 'A document failed:',  action )\n",
    "        except Exception as e:\n",
    "            \n",
    "            print(  \"\\nERROR Load Data Delete:\"  )\n",
    "            print( e )## quitar\n",
    "            #print(e) ## aqui se detiene si un documento en la lista no fue encontrado secuencialmente como va, podria fallar todo el bloque\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    metodos de reindexacion\n",
    "    \"\"\"\n",
    "    def reindex(  self,  indexSource,  indexDest  ):# arreglar par mas datos de 10000\n",
    "        \n",
    "        print(  \"Reindexando indice \",  indexSource,  \" a \" ,  indexDest  )\n",
    "        \n",
    "        total_success,  error  =  helpers.reindex(  client        =  self.__es,\n",
    "                                                    source_index  =  indexSource, \n",
    "                                                    target_index  =  indexDest,\n",
    "                                                    query         =  self.__queryReindex,\n",
    "                                                    target_client =  None,\n",
    "                                                    chunk_size    =  500,\n",
    "                                                    scroll        =  '5m',\n",
    "                                                    scan_kwargs   =  { },\n",
    "                                                    bulk_kwargs   =  { } )\n",
    "        \n",
    "        print(  \"total_docs_reindexados:\",  total_success  )\n",
    "        \n",
    "        return total_success\n",
    "    \n",
    "    \"\"\"\n",
    "    metodos para limpiar scroll\n",
    "    \"\"\"\n",
    "    def clear_scroll(self):\n",
    "        \n",
    "        self.__es.clear_scroll(  scroll_id  =  \"_all\"  )\n",
    "        print(  \"Se eliminaron todos los scrolls utilizados\"  )\n",
    "        \n",
    "    def clear_id_scroll(self):\n",
    "        \n",
    "        body_scroll  =  {  \"scroll_id\"  :  \"{0}\".format(  self.__idScroll  )  }\n",
    "        self.__es.clear_scroll(  body  =  body_scroll,  ignore  =  (  404,  400,  )  )\n",
    "        print(  \"Se elimino el scroll utilizado: \"  ,  self.__idScroll  )\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    metodos para extraer hists de elasticsearch\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_list_hits(self,indexName): \n",
    "        self.nameIndex  =  indexName\n",
    "        list_hits  =  [ ] \n",
    "        \n",
    "        try:\n",
    "            \n",
    "            if self.__es  !=  None:\n",
    "                \n",
    "                self.set_result( )\n",
    "                self.set_id_scroll()\n",
    "                list_hits  =  self.__resp[ \"hits\" ][ \"hits\" ]\n",
    "                self.show_total_hits( )\n",
    "                self.show_total_hits_ini( )\n",
    "                \n",
    "                hits  =  1\n",
    "                \n",
    "                while hits  >  0:\n",
    "                    otherRespHits  =  self.get_result_scroll( )\n",
    "                    hits           =  len(  otherRespHits  )\n",
    "                    print(  \"Next_hits: \"  ,  hits  )\n",
    "                    list_hits.extend(  otherRespHits  )\n",
    "                \n",
    "                self.show_id_scroll( )\n",
    "                self.clear_id_scroll( )\n",
    "            \n",
    "            else:\n",
    "                print(  \"Existe un error en la conexion a elasticsearch\"  )\n",
    "        \n",
    "        except exceptions as err:\n",
    "        \n",
    "            print( 'EC error: ',  err  )\n",
    "        \n",
    "        finally:\n",
    "            size  =  len(  list_hits  )\n",
    "            print(  \"total_final_hits:\"  ,  size  )\n",
    "            print(\"-----------------\")\n",
    "        return list_hits,size\n",
    "    \n",
    "    def delete_index(self, indexName):\n",
    "        self.nameIndex  =  indexName\n",
    "        self.__es.indices.delete(  index  =  self.nameIndex  )\n",
    "    \"\"\"\n",
    "    metodos para convertir dataframe a json\n",
    "    \"\"\"\n",
    "    def convert_df_to_json(  self,  df  ):\n",
    "        listStr         =  df.to_json(  orient  =  \"records\"  )\n",
    "        listJson        =  json.loads(  listStr )\n",
    "        return listJson\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
